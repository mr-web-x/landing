import os
from bs4 import BeautifulSoup
from collections import defaultdict
import re
from datetime import datetime
import xml.etree.ElementTree as ET

BLOG_DIR = "blog"
TYPY_POZICIEK_DIR = "typy-poziciek"  # –ù–æ–≤–∞—è –ø–∞–ø–∫–∞
INDEX_FILE = "index.html"
BLOG_PAGE_FILE = "blog.html"
TYPY_POZICIEK_PAGE_FILE = "typy-poziciek.html"  # –ù–æ–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
ACCORDION_ID = "blog-list"
BLOG_SECTION_ID = "blog"
BLOG_PAGE_SECTION_CLASS = "blog-content"
SITEMAP_FILE = "sitemap.xml"
SITE_URL = "https://fastcredit.sk"

def extract_section_content(html_content, section_id):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–µ–∫—Ü–∏–∏ –ø–æ –µ—ë ID"""
    soup = BeautifulSoup(html_content, "html.parser")
    section = soup.find("section", {"id": section_id})
    return str(section).strip() if section else ""

def extract_article_info(filepath, folder_name):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–∞—Ç—å–µ –∏–∑ HTML —Ñ–∞–π–ª–∞"""
    # –ü–æ–ª—É—á–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞
    filename = os.path.basename(filepath)
    
    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å "–ü–†–ò–ú–ï–†"
    if filename.startswith("–ü–†–ò–ú–ï–†"):
        return None
    
    with open(filepath, "r", encoding="utf-8") as file:
        soup = BeautifulSoup(file, "html.parser")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ h1
        h1 = soup.find("h1")
        title = h1.text.strip() if h1 else ""
        
        # –ï—Å–ª–∏ h1 –ø—É—Å—Ç–æ–π, –±–µ—Ä–µ–º –∏–∑ title
        if not title:
            title_tag = soup.find("title")
            if title_tag:
                title = title_tag.text.strip()
                # –£–±–∏—Ä–∞–µ–º —Å—É—Ñ—Ñ–∏–∫—Å —Å–∞–π—Ç–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
                title = title.split(" | ")[0].strip()
            
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ (–ø–µ—Ä–≤—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ –ø–æ—Å–ª–µ h1 –∏–ª–∏ meta description)
        meta_desc = soup.find("meta", {"name": "description"})
        description = ""
        
        if meta_desc and meta_desc.get("content"):
            description = meta_desc["content"].strip()
        else:
            # –ò—â–µ–º –ø–µ—Ä–≤—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ –ø–æ—Å–ª–µ h1
            if h1:
                next_p = h1.find_next_sibling("p")
                if next_p:
                    description = next_p.text.strip()[:200] + "..." if len(next_p.text) > 200 else next_p.text.strip()
        
        return {
            "title": title,
            "description": description,
            "filename": filename,
            "href": f"/{folder_name}/{filename}"
        }

def generate_blog_slider_html(articles):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML –¥–ª—è —Å–ª–∞–π–¥–µ—Ä–∞ –±–ª–æ–≥–∞ –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
    slides_html = ""
    
    for article in articles:
        slide = f'''                <div class="swiper-slide">
                  <a href="{article['href']}" class="blog-card">
                    <img
                      src="/assets/blog/b1.webp"
                      alt="articles"
                      loading="lazy"
                    />
                    <h3>{article['title']}</h3>
                    <p>{article['description']}</p>
                    <div class="blog-card-bottom">
                      <span>Podrobnosti ‚Üí</span>
                    </div>
                  </a>
                </div>
'''
        slides_html += slide
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—É—é —Å–µ–∫—Ü–∏—é
    section_html = f'''      <section id="blog" class="blog-home">
        <div class="container">
          <h2>N√°≈° blog</h2>
          <div class="blog-home__wrapper">
            <div class="swiper blogSwiper">
              <div class="swiper-wrapper">
{slides_html.rstrip()}
              </div>
              <div class="swiper-button-next"></div>
              <div class="swiper-button-prev"></div>
              <div class="swiper-pagination"></div>
            </div>
          </div>
        </div>
      </section>'''
    
    return section_html

def generate_blog_page_html(articles):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã –±–ª–æ–≥–∞"""
    cards_html = ""
    
    for article in articles:
        card = f'''            <a
              class="blog-content__card"
              href="{article['href']}"
            >
              <img alt="articles" loading="lazy" src="/assets/blog/b1.webp" />
              <h3>
                {article['title']}
              </h3>
              <p>
                {article['description']}
              </p>
              <div class="blog-card-bottom">
                <span>Podrobnosti ‚Üí</span>
              </div>
            </a>
'''
        cards_html += card
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—É—é —Å–µ–∫—Ü–∏—é –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã –±–ª–æ–≥–∞
    section_html = f'''      <section class="blog-content">
        <div class="container">
          <h1>N√°≈° blog</h1>
          <div class="blog-content__list">
{cards_html.rstrip()}
          </div>
        </div>
      </section>'''
    
    return section_html

def generate_typy_poziciek_page_html(articles):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã typy-poziciek"""
    cards_html = ""
    
    for article in articles:
        card = f'''            <a
              class="blog-content__card"
              href="{article['href']}"
            >
              <img alt="articles" loading="lazy" src="/assets/blog/b1.webp" />
              <h3>
                {article['title']}
              </h3>
              <p>
                {article['description']}
              </p>
              <div class="blog-card-bottom">
                <span>Podrobnosti ‚Üí</span>
              </div>
            </a>
'''
        cards_html += card
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—É—é —Å–µ–∫—Ü–∏—é –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã typy-poziciek
    section_html = f'''      <section class="blog-content">
        <div class="container">
          <h1>Typy p√¥≈æiƒçiek</h1>
          <div class="blog-content__list">
{cards_html.rstrip()}
          </div>
        </div>
      </section>'''
    
    return section_html

def find_unique_section():
    """–ù–∞—Ö–æ–¥–∏—Ç —É–Ω–∏–∫–∞–ª—å–Ω—É—é —Å–µ–∫—Ü–∏—é blog-list —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –±–ª–æ–≥–∞"""
    content_map = defaultdict(list)
    
    # –°–∫–∞–Ω–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–∞–ø–∫—É blog –¥–ª—è –ø–æ–∏—Å–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ–π —Å–µ–∫—Ü–∏–∏
    if not os.path.exists(BLOG_DIR):
        print(f"‚ö†Ô∏è –ü–∞–ø–∫–∞ {BLOG_DIR} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return None
    
    for filename in os.listdir(BLOG_DIR):
        if filename.endswith(".html"):
            path = os.path.join(BLOG_DIR, filename)
            with open(path, "r", encoding="utf-8") as file:
                html = file.read()
                section_html = extract_section_content(html, ACCORDION_ID)
                if section_html:
                    content_map[section_html].append(filename)

    if len(content_map) == 0:
        print("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–µ–∫—Ü–∏–π blog-list –≤ –ø–∞–ø–∫–µ blog")
        return None

    if len(content_map) == 1:
        print("‚ö†Ô∏è –í—Å–µ —Å–µ–∫—Ü–∏–∏ blog-list –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ ‚Äî –Ω–µ—á–µ–≥–æ –æ–±–Ω–æ–≤–ª—è—Ç—å.")
        return None

    for content, files in content_map.items():
        if len(files) == 1:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ —É–Ω–∏–∫–∞–ª—å–Ω–∞—è —Å–µ–∫—Ü–∏—è blog-list –≤ —Ñ–∞–π–ª–µ: {files[0]}")
            return content

    print("‚ùå –ù–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–π —Å–µ–∫—Ü–∏–∏ blog-list ‚Äî –ª–∏–±–æ –≤—Å–µ —Ä–∞–∑–Ω—ã–µ, –ª–∏–±–æ –ø–æ–≤—Ç–æ—Ä—è—é—Ç—Å—è –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫—É —Ä–∞–∑.")
    return None

def update_articles_in_folder(folder_path, folder_name, new_section_html):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–µ–∫—Ü–∏—é blog-list –≤–æ –≤—Å–µ—Ö —Ñ–∞–π–ª–∞—Ö —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–∏"""
    if not os.path.exists(folder_path):
        print(f"‚ö†Ô∏è –ü–∞–ø–∫–∞ {folder_path} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return 0
    
    updated_count = 0
    
    for filename in os.listdir(folder_path):
        if filename.endswith(".html"):
            path = os.path.join(folder_path, filename)
            with open(path, "r", encoding="utf-8") as file:
                soup = BeautifulSoup(file, "html.parser")
            
            old_section = soup.find("section", {"id": ACCORDION_ID})
            if old_section:
                new_section_soup = BeautifulSoup(new_section_html, "html.parser")
                old_section.replace_with(new_section_soup)
                
                with open(path, "w", encoding="utf-8") as file:
                    file.write(str(soup))
                updated_count += 1
                print(f"  ‚úì –û–±–Ω–æ–≤–ª–µ–Ω —Ñ–∞–π–ª: {folder_name}/{filename}")
    
    return updated_count

def sync_blog_list_sections():
    """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç —Å–µ–∫—Ü–∏–∏ blog-list –º–µ–∂–¥—É –≤—Å–µ–º–∏ —Ñ–∞–π–ª–∞–º–∏ –≤ –æ–±–µ–∏—Ö –ø–∞–ø–∫–∞—Ö"""
    print("\nüìã –≠—Ç–∞–ø 5: –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å–µ–∫—Ü–∏–π <section id='blog-list'>...")
    
    # –ò—â–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—É—é —Å–µ–∫—Ü–∏—é —Ç–æ–ª—å–∫–æ –≤ –ø–∞–ø–∫–µ blog
    new_section_html = find_unique_section()
    
    if not new_section_html:
        return False
    
    total_updated = 0
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ blog
    print("üîÑ –û–±–Ω–æ–≤–ª—è—é —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ blog...")
    blog_updated = update_articles_in_folder(BLOG_DIR, "blog", new_section_html)
    total_updated += blog_updated
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ typy-poziciek
    print("üîÑ –û–±–Ω–æ–≤–ª—è—é —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ typy-poziciek...")
    typy_updated = update_articles_in_folder(TYPY_POZICIEK_DIR, "typy-poziciek", new_section_html)
    total_updated += typy_updated
    
    if total_updated > 0:
        print(f"‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±–Ω–æ–≤–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤:")
        print(f"   - blog: {blog_updated}")
        print(f"   - typy-poziciek: {typy_updated}")
        print(f"   - –í—Å–µ–≥–æ: {total_updated}")
        return True
    else:
        print("‚ö†Ô∏è –ù–∏ –æ–¥–∏–Ω —Ñ–∞–π–ª –Ω–µ –±—ã–ª –æ–±–Ω–æ–≤–ª–µ–Ω")
        return False

def get_articles_from_folder(folder_path, folder_name):
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–∏"""
    articles = []
    
    if not os.path.exists(folder_path):
        print(f"‚ö†Ô∏è –ü–∞–ø–∫–∞ {folder_path} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return articles
    
    for filename in sorted(os.listdir(folder_path)):
        if filename.endswith(".html"):
            path = os.path.join(folder_path, filename)
            article_info = extract_article_info(path, folder_name)
            if article_info:  # None –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "–ü–†–ò–ú–ï–†"
                articles.append(article_info)
    
    return articles

def update_index_blog_section():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–µ–∫—Ü–∏—é –±–ª–æ–≥–∞ –≤ index.html –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –∏–∑ –ø–∞–ø–∫–∏ blog"""
    articles = get_articles_from_folder(BLOG_DIR, "blog")
    
    if not articles:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤ index.html")
        return False
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–π HTML –¥–ª—è —Å–µ–∫—Ü–∏–∏ –±–ª–æ–≥–∞
    new_blog_section = generate_blog_slider_html(articles)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º index.html
    try:
        with open(INDEX_FILE, "r", encoding="utf-8") as file:
            soup = BeautifulSoup(file, "html.parser")
        
        old_section = soup.find("section", {"id": BLOG_SECTION_ID})
        if old_section:
            new_section_soup = BeautifulSoup(new_blog_section, "html.parser")
            old_section.replace_with(new_section_soup)
            
            with open(INDEX_FILE, "w", encoding="utf-8") as file:
                file.write(str(soup))
            
            print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–∞ —Å–µ–∫—Ü–∏—è –±–ª–æ–≥–∞ –≤ index.html ({len(articles)} —Å—Ç–∞—Ç–µ–π)")
            return True
        else:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–∞ —Å–µ–∫—Ü–∏—è –±–ª–æ–≥–∞ –≤ index.html")
            return False
            
    except FileNotFoundError:
        print(f"‚ùå –§–∞–π–ª {INDEX_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ index.html: {e}")
        return False

def update_blog_page_section():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–µ–∫—Ü–∏—é –±–ª–æ–≥–∞ –≤ blog.html –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–µ–π –∏–∑ –ø–∞–ø–∫–∏ blog"""
    articles = get_articles_from_folder(BLOG_DIR, "blog")
    
    if not articles:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤ blog.html")
        return False
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–π HTML –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã –±–ª–æ–≥–∞
    new_blog_section = generate_blog_page_html(articles)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º blog.html
    try:
        with open(BLOG_PAGE_FILE, "r", encoding="utf-8") as file:
            soup = BeautifulSoup(file, "html.parser")
        
        old_section = soup.find("section", {"class": BLOG_PAGE_SECTION_CLASS})
        if old_section:
            new_section_soup = BeautifulSoup(new_blog_section, "html.parser")
            new_section_soup = new_section_soup.find("section")  # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–µ–∫—Ü–∏—é
            old_section.replace_with(new_section_soup)
            
            with open(BLOG_PAGE_FILE, "w", encoding="utf-8") as file:
                file.write(str(soup))
            
            print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –±–ª–æ–≥–∞ –≤ blog.html ({len(articles)} —Å—Ç–∞—Ç–µ–π)")
            return True
        else:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–∞ —Å–µ–∫—Ü–∏—è –±–ª–æ–≥–∞ –≤ blog.html")
            return False
            
    except FileNotFoundError:
        print(f"‚ùå –§–∞–π–ª {BLOG_PAGE_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ blog.html: {e}")
        return False

def update_typy_poziciek_page_section():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–µ–∫—Ü–∏—é –≤ typy-poziciek.html –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–µ–π –∏–∑ –ø–∞–ø–∫–∏ typy-poziciek"""
    articles = get_articles_from_folder(TYPY_POZICIEK_DIR, "typy-poziciek")
    
    if not articles:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤ typy-poziciek.html")
        return False
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–π HTML –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã typy-poziciek
    new_section = generate_typy_poziciek_page_html(articles)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º typy-poziciek.html
    try:
        with open(TYPY_POZICIEK_PAGE_FILE, "r", encoding="utf-8") as file:
            soup = BeautifulSoup(file, "html.parser")
        
        old_section = soup.find("section", {"class": BLOG_PAGE_SECTION_CLASS})
        if old_section:
            new_section_soup = BeautifulSoup(new_section, "html.parser")
            new_section_soup = new_section_soup.find("section")  # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–µ–∫—Ü–∏—é
            old_section.replace_with(new_section_soup)
            
            with open(TYPY_POZICIEK_PAGE_FILE, "w", encoding="utf-8") as file:
                file.write(str(soup))
            
            print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ typy-poziciek –≤ typy-poziciek.html ({len(articles)} —Å—Ç–∞—Ç–µ–π)")
            return True
        else:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–∞ —Å–µ–∫—Ü–∏—è –≤ typy-poziciek.html")
            return False
            
    except FileNotFoundError:
        print(f"‚ùå –§–∞–π–ª {TYPY_POZICIEK_PAGE_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ typy-poziciek.html: {e}")
        return False

def update_sitemap():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç sitemap.xml, –¥–æ–±–∞–≤–ª—è—è –Ω–æ–≤—ã–µ —Å—Ç–∞—Ç—å–∏ –∏–∑ –æ–±–µ–∏—Ö –ø–∞–ø–æ–∫"""
    try:
        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º namespace –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å XML
        ET.register_namespace('', 'http://www.sitemaps.org/schemas/sitemap/0.9')
        ET.register_namespace('xsi', 'http://www.w3.org/2001/XMLSchema-instance')
        
        # –ü–∞—Ä—Å–∏–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π sitemap
        tree = ET.parse(SITEMAP_FILE)
        root = tree.getroot()
        
        # –ü–æ–ª—É—á–∞–µ–º namespace
        ns = {'': 'http://www.sitemaps.org/schemas/sitemap/0.9'}
        
        # –°–æ–±–∏—Ä–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ URL –∏–∑ sitemap
        existing_urls = set()
        for url in root.findall('url', ns):
            loc = url.find('loc', ns)
            if loc is not None and loc.text:
                existing_urls.add(loc.text.strip())
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ ISO
        current_date = datetime.now().strftime('%Y-%m-%dT%H:%M:%S+00:00')
        
        new_articles_count = 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—å–∏ –∏–∑ –ø–∞–ø–∫–∏ blog
        if os.path.exists(BLOG_DIR):
            for filename in sorted(os.listdir(BLOG_DIR)):
                if filename.endswith(".html") and not filename.startswith("–ü–†–ò–ú–ï–†"):
                    article_url = f"{SITE_URL}/blog/{filename}"
                    
                    if article_url not in existing_urls:
                        url_elem = ET.SubElement(root, 'url')
                        
                        loc_elem = ET.SubElement(url_elem, 'loc')
                        loc_elem.text = f" {article_url}"
                        
                        lastmod_elem = ET.SubElement(url_elem, 'lastmod')
                        lastmod_elem.text = current_date
                        
                        priority_elem = ET.SubElement(url_elem, 'priority')
                        priority_elem.text = '0.80'
                        
                        new_articles_count += 1
                        print(f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è —Å—Ç–∞—Ç—å—è –≤ sitemap: blog/{filename}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—å–∏ –∏–∑ –ø–∞–ø–∫–∏ typy-poziciek
        if os.path.exists(TYPY_POZICIEK_DIR):
            for filename in sorted(os.listdir(TYPY_POZICIEK_DIR)):
                if filename.endswith(".html") and not filename.startswith("–ü–†–ò–ú–ï–†"):
                    article_url = f"{SITE_URL}/typy-poziciek/{filename}"
                    
                    if article_url not in existing_urls:
                        url_elem = ET.SubElement(root, 'url')
                        
                        loc_elem = ET.SubElement(url_elem, 'loc')
                        loc_elem.text = f" {article_url}"
                        
                        lastmod_elem = ET.SubElement(url_elem, 'lastmod')
                        lastmod_elem.text = current_date
                        
                        priority_elem = ET.SubElement(url_elem, 'priority')
                        priority_elem.text = '0.80'
                        
                        new_articles_count += 1
                        print(f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è —Å—Ç–∞—Ç—å—è –≤ sitemap: typy-poziciek/{filename}")
        
        if new_articles_count > 0:
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º XML —Å –æ—Ç—Å—Ç—É–ø–∞–º–∏
            indent_xml(root)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π sitemap
            tree.write(SITEMAP_FILE, encoding='UTF-8', xml_declaration=True)
            print(f"‚úÖ Sitemap –æ–±–Ω–æ–≤–ª–µ–Ω! –î–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö URL: {new_articles_count}")
        else:
            print("‚ÑπÔ∏è –ù–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ sitemap –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        return True
        
    except FileNotFoundError:
        print(f"‚ùå –§–∞–π–ª {SITEMAP_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ sitemap: {e}")
        return False

def indent_xml(elem, level=0):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –æ—Ç—Å—Ç—É–ø—ã –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è XML"""
    i = "\n" + level * "  "
    if len(elem):
        if not elem.text or not elem.text.strip():
            elem.text = i + "  "
        if not elem.tail or not elem.tail.strip():
            elem.tail = i
        for child in elem:
            indent_xml(child, level + 1)
        if not elem.tail or not elem.tail.strip():
            elem.tail = i
    else:
        if level and (not elem.tail or not elem.tail.strip()):
            elem.tail = i

if __name__ == "__main__":
    print("="*50)
    print("üöÄ –ó–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –±–ª–æ–≥–∞")
    print("="*50)
    
    # –≠—Ç–∞–ø 1: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ª–∞–π–¥–µ—Ä–∞ –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
    print("\nüìã –≠—Ç–∞–ø 1: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ª–∞–π–¥–µ—Ä–∞ –±–ª–æ–≥–∞ –≤ index.html...")
    if update_index_blog_section():
        print("üéâ –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞!")
    
    # –≠—Ç–∞–ø 2: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –±–ª–æ–≥–∞
    print("\nüìã –≠—Ç–∞–ø 2: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –±–ª–æ–≥–∞ –≤ blog.html...")
    if update_blog_page_section():
        print("üéâ –°—Ç—Ä–∞–Ω–∏—Ü–∞ –±–ª–æ–≥–∞ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞!")
    
    # –≠—Ç–∞–ø 3: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã typy-poziciek
    print("\nüìã –≠—Ç–∞–ø 3: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã typy-poziciek –≤ typy-poziciek.html...")
    if update_typy_poziciek_page_section():
        print("üéâ –°—Ç—Ä–∞–Ω–∏—Ü–∞ typy-poziciek —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞!")
    
    # –≠—Ç–∞–ø 4: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ sitemap.xml
    print("\nüìã –≠—Ç–∞–ø 4: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ sitemap.xml...")
    if update_sitemap():
        print("üó∫Ô∏è –ö–∞—Ä—Ç–∞ —Å–∞–π—Ç–∞ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞!")
    
    # –≠—Ç–∞–ø 5: –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å–µ–∫—Ü–∏–π blog-list
    if sync_blog_list_sections():
        print("üîó –°–µ–∫—Ü–∏–∏ blog-list —É—Å–ø–µ—à–Ω–æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã!")
    
    print("\n‚ú® –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")