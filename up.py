import os
from bs4 import BeautifulSoup
from collections import defaultdict
import re

BLOG_DIR = "blog"
INDEX_FILE = "index.html"
ACCORDION_ID = "blog-list"
BLOG_SECTION_ID = "blog"

def extract_section_content(html_content, section_id):
    soup = BeautifulSoup(html_content, "html.parser")
    section = soup.find("section", {"id": section_id})
    return str(section).strip() if section else ""

def extract_article_info(filepath):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–∞—Ç—å–µ –∏–∑ HTML —Ñ–∞–π–ª–∞"""
    # –ü–æ–ª—É—á–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞
    filename = os.path.basename(filepath)
    
    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å "–ü–†–ò–ú–ï–†"
    if filename.startswith("–ü–†–ò–ú–ï–†"):
        return None
    
    with open(filepath, "r", encoding="utf-8") as file:
        soup = BeautifulSoup(file, "html.parser")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ h1
        h1 = soup.find("h1")
        title = h1.text.strip() if h1 else ""
        
        # –ï—Å–ª–∏ h1 –ø—É—Å—Ç–æ–π, –±–µ—Ä–µ–º –∏–∑ title
        if not title:
            title_tag = soup.find("title")
            if title_tag:
                title = title_tag.text.strip()
                # –£–±–∏—Ä–∞–µ–º —Å—É—Ñ—Ñ–∏–∫—Å —Å–∞–π—Ç–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
                title = title.split(" | ")[0].strip()
            
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ (–ø–µ—Ä–≤—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ –ø–æ—Å–ª–µ h1 –∏–ª–∏ meta description)
        meta_desc = soup.find("meta", {"name": "description"})
        description = ""
        
        if meta_desc and meta_desc.get("content"):
            description = meta_desc["content"].strip()
        else:
            # –ò—â–µ–º –ø–µ—Ä–≤—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ –ø–æ—Å–ª–µ h1
            if h1:
                next_p = h1.find_next_sibling("p")
                if next_p:
                    description = next_p.text.strip()[:200] + "..." if len(next_p.text) > 200 else next_p.text.strip()
        
        return {
            "title": title,
            "description": description,
            "filename": filename,
            "href": f"/blog/{filename}"
        }

def generate_blog_slider_html(articles):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML –¥–ª—è —Å–ª–∞–π–¥–µ—Ä–∞ –±–ª–æ–≥–∞"""
    slides_html = ""
    
    for article in articles:
        slide = f'''                <div class="swiper-slide">
                  <a href="{article['href']}" class="blog-card">
                    <img
                      src="/assets/blog/b1.webp"
                      alt="articles"
                      loading="lazy"
                    />
                    <h3>{article['title']}</h3>
                    <p>{article['description']}</p>
                    <div class="blog-card-bottom">
                      <span>Podrobnosti ‚Üí</span>
                    </div>
                  </a>
                </div>
'''
        slides_html += slide
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—É—é —Å–µ–∫—Ü–∏—é
    section_html = f'''      <section id="blog" class="blog-home">
        <div class="container">
          <h2>N√°≈° blog</h2>
          <div class="blog-home__wrapper">
            <div class="swiper blogSwiper">
              <div class="swiper-wrapper">
{slides_html.rstrip()}
              </div>
              <div class="swiper-button-next"></div>
              <div class="swiper-button-prev"></div>
              <div class="swiper-pagination"></div>
            </div>
          </div>
        </div>
      </section>'''
    
    return section_html

def find_unique_section():
    """–ù–∞—Ö–æ–¥–∏—Ç —É–Ω–∏–∫–∞–ª—å–Ω—É—é —Å–µ–∫—Ü–∏—é blog-list —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –±–ª–æ–≥–∞"""
    content_map = defaultdict(list)
    
    for filename in os.listdir(BLOG_DIR):
        if filename.endswith(".html"):
            path = os.path.join(BLOG_DIR, filename)
            with open(path, "r", encoding="utf-8") as file:
                html = file.read()
                section_html = extract_section_content(html, ACCORDION_ID)
                if section_html:
                    content_map[section_html].append(filename)

    if len(content_map) == 1:
        print("‚ö†Ô∏è –í—Å–µ —Å–µ–∫—Ü–∏–∏ blog-list –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ ‚Äî –Ω–µ—á–µ–≥–æ –æ–±–Ω–æ–≤–ª—è—Ç—å.")
        return None

    for content, files in content_map.items():
        if len(files) == 1:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ —É–Ω–∏–∫–∞–ª—å–Ω–∞—è —Å–µ–∫—Ü–∏—è blog-list –≤ —Ñ–∞–π–ª–µ: {files[0]}")
            return content

    print("‚ùå –ù–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–π —Å–µ–∫—Ü–∏–∏ blog-list ‚Äî –ª–∏–±–æ –≤—Å–µ —Ä–∞–∑–Ω—ã–µ, –ª–∏–±–æ –ø–æ–≤—Ç–æ—Ä—è—é—Ç—Å—è –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫—É —Ä–∞–∑.")
    return None

def update_all_articles(new_section_html):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–µ–∫—Ü–∏—é blog-list –≤–æ –≤—Å–µ—Ö —Ñ–∞–π–ª–∞—Ö –±–ª–æ–≥–∞"""
    updated_count = 0
    
    for filename in os.listdir(BLOG_DIR):
        if filename.endswith(".html"):
            path = os.path.join(BLOG_DIR, filename)
            with open(path, "r", encoding="utf-8") as file:
                soup = BeautifulSoup(file, "html.parser")
            
            old_section = soup.find("section", {"id": ACCORDION_ID})
            if old_section:
                new_section_soup = BeautifulSoup(new_section_html, "html.parser")
                old_section.replace_with(new_section_soup)
                
                with open(path, "w", encoding="utf-8") as file:
                    file.write(str(soup))
                updated_count += 1
    
    return updated_count

def update_index_blog_section():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–µ–∫—Ü–∏—é –±–ª–æ–≥–∞ –≤ index.html –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π"""
    # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Å–µ—Ö —Å—Ç–∞—Ç—å—è—Ö
    articles = []
    
    for filename in sorted(os.listdir(BLOG_DIR)):
        if filename.endswith(".html"):
            path = os.path.join(BLOG_DIR, filename)
            article_info = extract_article_info(path)
            if article_info:  # None –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "–ü–†–ò–ú–ï–†"
                articles.append(article_info)
    
    if not articles:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤ index.html")
        return False
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–π HTML –¥–ª—è —Å–µ–∫—Ü–∏–∏ –±–ª–æ–≥–∞
    new_blog_section = generate_blog_slider_html(articles)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º index.html
    try:
        with open(INDEX_FILE, "r", encoding="utf-8") as file:
            soup = BeautifulSoup(file, "html.parser")
        
        old_section = soup.find("section", {"id": BLOG_SECTION_ID})
        if old_section:
            new_section_soup = BeautifulSoup(new_blog_section, "html.parser")
            old_section.replace_with(new_section_soup)
            
            with open(INDEX_FILE, "w", encoding="utf-8") as file:
                file.write(str(soup))
            
            print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–∞ —Å–µ–∫—Ü–∏—è –±–ª–æ–≥–∞ –≤ index.html ({len(articles)} —Å—Ç–∞—Ç–µ–π)")
            return True
        else:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–∞ —Å–µ–∫—Ü–∏—è –±–ª–æ–≥–∞ –≤ index.html")
            return False
            
    except FileNotFoundError:
        print(f"‚ùå –§–∞–π–ª {INDEX_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ index.html: {e}")
        return False

if __name__ == "__main__":
    print("="*50)
    print("üöÄ –ó–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –±–ª–æ–≥–∞")
    print("="*50)
    
    # –≠—Ç–∞–ø 1: –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å–µ–∫—Ü–∏–π blog-list
    print("\nüìã –≠—Ç–∞–ø 1: –ü–æ–∏—Å–∫ —É–Ω–∏–∫–∞–ª—å–Ω–æ–π —Å–µ–∫—Ü–∏–∏ <section id='blog-list'>...")
    new_accordion_html = find_unique_section()
    
    if new_accordion_html:
        print("üîÑ –û–±–Ω–æ–≤–ª—è—é –≤—Å–µ —Å—Ç–∞—Ç—å–∏ –Ω–æ–≤–æ–π —Å–µ–∫—Ü–∏–µ–π blog-list...")
        updated = update_all_articles(new_accordion_html)
        print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ {updated} —Ñ–∞–π–ª–æ–≤!")
    
    # –≠—Ç–∞–ø 2: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ª–∞–π–¥–µ—Ä–∞ –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
    print("\nüìã –≠—Ç–∞–ø 2: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ª–∞–π–¥–µ—Ä–∞ –±–ª–æ–≥–∞ –≤ index.html...")
    if update_index_blog_section():
        print("üéâ –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞!")
    
    print("\n‚ú® –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")